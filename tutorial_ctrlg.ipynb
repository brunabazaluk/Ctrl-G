{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ctrl-G Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part A**. Ctrl-G on GPT2-large (less computation required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. load pretrained models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bazaluk/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "device = 'cuda'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # set your cuda device\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "import ctrlg\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList\n",
    "\n",
    "# load the pretrained base_model and hmm_model; see README.md for a complete list of \n",
    "# released checkpoints. note that the hmm_model and base_model must share the same \n",
    "# vocabulary of tokens: i.e., one cannot apply hmm_gpt2-large_common-gen_4096 to \n",
    "# tulu2-7b_writing-prompts. To apply Ctrl-G to a custom base_model or to achieve \n",
    "# best performance on a specific domain, users would need to distill an hmm_model\n",
    "# from the base_model. Please refer to tutorial_distillation.ipynb for details.\n",
    "BASE_MODEL_PATH = f'ctrlg/gpt2-large_common-gen' # a gpt2-large checkpoint domain adapted to the common-gen corpus\n",
    "HMM_MODEL_PATH = f'ctrlg/hmm_gpt2-large_common-gen_4096' # alternatively 'ctrlg/hmm_gpt2-large_common-gen_32768' for better quality\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH).to(device)\n",
    "base_model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "hmm_model = ctrlg.HMM.from_pretrained(HMM_MODEL_PATH).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. specify logical constraints as DFAs (example constraint 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8600]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = hmm_model.vocab_size\n",
    "a =ctrlg.populate_edge([\"Step\"], vocab_size, tokenizer)\n",
    "[i for i, x in enumerate(a) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 478, 29945]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"V5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "\n",
    "##################################### prefix, suffix, prompt #####################################\n",
    "prefix = \"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\"\n",
    "\n",
    "#\"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%.Is ringing alarm more likely than silent alarm overall?Guidance: Address the question by following the steps below:\\nStep 1) Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas. Step 2) Determine the query type: Identify the type of query implied by the main question. Choices include 'marginal probability', 'conditional probability', 'explaining away effect', 'backdoor adjustment set', 'average treatment effect', 'collider bias', 'normal counterfactual question', 'average treatment effect on treated', 'natural direct effect' or 'natural indirect effect'. Your answer should only be a term from the list above, enclosed in quotation marks. Step 3) Formalize the query: Translate the query into its formal mathematical expression based on its type, utilizing the 'do(·)' notation or counterfactual notations as needed. Step 4) Extract all the available data. Your answer should contain nothing but marginal probabilities and conditional probabilities in the form 'P(...)=...' or 'P(...|...)=...', each probability being separated by a semicolon. Stick to the previously mentioned denotations for the variables. Step 5) Given all the information above, deduce the estimand using skills such as do-calculus, counterfactual prediction, and the basics of probabilities. Answer step by step. Step 6) Insert the relevant data in Step 4 into the estimand, perform basic arithmetic calculations, and derive the final answer. There is an identifiable answer. Answer step by step. \\nBased on all the reasoning above, output one word to answer the initial question.\" # generate text starting with nothing\n",
    "suffix = '<|endoftext|>' # generate text ending with '<|endoftext|>'; a suffix must end with the eos token\n",
    "#prompt = \"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%.Is ringing alarm more likely than silent alarm overall?Guidance: Address the question by following the steps below:\\nStep 1) Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas. Step 2) Determine the query type: Identify the type of query implied by the main question. Choices include 'marginal probability', 'conditional probability', 'explaining away effect', 'backdoor adjustment set', 'average treatment effect', 'collider bias', 'normal counterfactual question', 'average treatment effect on treated', 'natural direct effect' or 'natural indirect effect'. Your answer should only be a term from the list above, enclosed in quotation marks. Step 3) Formalize the query: Translate the query into its formal mathematical expression based on its type, utilizing the 'do(·)' notation or counterfactual notations as needed. Step 4) Extract all the available data. Your answer should contain nothing but marginal probabilities and conditional probabilities in the form 'P(...)=...' or 'P(...|...)=...', each probability being separated by a semicolon. Stick to the previously mentioned denotations for the variables. Step 5) Given all the information above, deduce the estimand using skills such as do-calculus, counterfactual prediction, and the basics of probabilities. Answer step by step. Step 6) Insert the relevant data in Step 4 into the estimand, perform basic arithmetic calculations, and derive the final answer. There is an identifiable answer. Answer step by step:<|endoftext|>\"\n",
    "prompt = \"Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas.<|endoftext|>\"\n",
    "# prompt the base model with the '<|endoftext|>' token\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)\n",
    "suffix_ids = tokenizer.encode(suffix)\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "##################################### prefix, suffix, prompt #####################################\n",
    "##################################### DFA Construction #####################################\n",
    "# ac_builder constructs a DFA representing the constraint that (at least) \n",
    "# one the patterns must appear; a pattern is a sequence of token ids\n",
    "ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "# word_count_builder constructs a DFA representing the constraint that \n",
    "# the generated text consists of a to b words; refer to the source code of\n",
    "# WordCountBuilder for the definition of a word.\n",
    "word_count_builder = ctrlg.WordCountBuilder(tokenizer, vocab_size)\n",
    "\n",
    "dfa_graphs = []\n",
    "\n",
    "# constraint 1:\n",
    "# one of ' riding a bike', ' ride bikes', ' rides a bike', ' biking', ' bikes' has to appear\n",
    "# AND one of ' park', ' beach' has to appear\n",
    "keyphrases = [[' X ', ' Y ', ' V2 '],\n",
    "            [' ->'],\n",
    "             [' X ', ' Y ', ' V2 ']]\n",
    "\n",
    "\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x) for x in keyphrase]\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "\n",
    "# constraint 2: generate exactly 10 words\n",
    "# word_count_builder constructs a DFA representing the constraint that \n",
    "# the generated text must contain a to b words\n",
    "a, b = 3, 20\n",
    "dfa_graphs.append(word_count_builder.build(a, b))\n",
    "\n",
    "# taking the intersection of the DFAs, i.e., \"logical and\" of the constraints.\n",
    "# This function also minimizes the constructed DFA, which is mainly CPU-based operations;\n",
    "# Due to its pure python implemenation, DFA minimization can be slow for complex constraints\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "\n",
    "# compile the dfa_graph for efficient GPU execution\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "##################################### DFA Construction #####################################\n",
    "\n",
    "\n",
    "##################################### token length #####################################\n",
    "# specify the min_new_tokens and max_new_tokens to be generated (excluding\n",
    "# the prefix and suffix) make sure that the numbers here would not conflict\n",
    "# with the given constraint: e.g. ask the model to generate 10 words with\n",
    "# max_new_tokens = 8\n",
    "min_new_tokens = 5\n",
    "max_new_tokens = 32\n",
    "##################################### token length #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "\n",
    "##################################### prefix, suffix, prompt #####################################\n",
    "prefix = ''\n",
    "#\"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%.Is ringing alarm more likely than silent alarm overall?Guidance: Address the question by following the steps below:\\nStep 1) Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas. Step 2) Determine the query type: Identify the type of query implied by the main question. Choices include 'marginal probability', 'conditional probability', 'explaining away effect', 'backdoor adjustment set', 'average treatment effect', 'collider bias', 'normal counterfactual question', 'average treatment effect on treated', 'natural direct effect' or 'natural indirect effect'. Your answer should only be a term from the list above, enclosed in quotation marks. Step 3) Formalize the query: Translate the query into its formal mathematical expression based on its type, utilizing the 'do(·)' notation or counterfactual notations as needed. Step 4) Extract all the available data. Your answer should contain nothing but marginal probabilities and conditional probabilities in the form 'P(...)=...' or 'P(...|...)=...', each probability being separated by a semicolon. Stick to the previously mentioned denotations for the variables. Step 5) Given all the information above, deduce the estimand using skills such as do-calculus, counterfactual prediction, and the basics of probabilities. Answer step by step. Step 6) Insert the relevant data in Step 4 into the estimand, perform basic arithmetic calculations, and derive the final answer. There is an identifiable answer. Answer step by step. \\nBased on all the reasoning above, output one word to answer the initial question.\" # generate text starting with nothing\n",
    "suffix = '<|endoftext|>' # generate text ending with '<|endoftext|>'; a suffix must end with the eos token\n",
    "#prompt = \"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%.Is ringing alarm more likely than silent alarm overall?Guidance: Address the question by following the steps below:\\nStep 1) Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas. Step 2) Determine the query type: Identify the type of query implied by the main question. Choices include 'marginal probability', 'conditional probability', 'explaining away effect', 'backdoor adjustment set', 'average treatment effect', 'collider bias', 'normal counterfactual question', 'average treatment effect on treated', 'natural direct effect' or 'natural indirect effect'. Your answer should only be a term from the list above, enclosed in quotation marks. Step 3) Formalize the query: Translate the query into its formal mathematical expression based on its type, utilizing the 'do(·)' notation or counterfactual notations as needed. Step 4) Extract all the available data. Your answer should contain nothing but marginal probabilities and conditional probabilities in the form 'P(...)=...' or 'P(...|...)=...', each probability being separated by a semicolon. Stick to the previously mentioned denotations for the variables. Step 5) Given all the information above, deduce the estimand using skills such as do-calculus, counterfactual prediction, and the basics of probabilities. Answer step by step. Step 6) Insert the relevant data in Step 4 into the estimand, perform basic arithmetic calculations, and derive the final answer. There is an identifiable answer. Answer step by step:<|endoftext|>\"\n",
    "prompt = \"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas.<|endoftext|>\"\n",
    "# prompt the base model with the '<|endoftext|>' token\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)\n",
    "suffix_ids = tokenizer.encode(suffix)\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "##################################### prefix, suffix, prompt #####################################\n",
    "\n",
    "\n",
    "##################################### DFA Construction #####################################\n",
    "# ac_builder constructs a DFA representing the constraint that (at least) \n",
    "# one the patterns must appear; a pattern is a sequence of token ids\n",
    "#ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "\n",
    "# word_count_builder constructs a DFA representing the constraint that \n",
    "# the generated text consists of a to b words; refer to the source code of\n",
    "# WordCountBuilder for the definition of a word.\n",
    "#word_count_builder = ctrlg.WordCountBuilder(tokenizer, vocab_size)\n",
    "\n",
    "#dfa_graphs = []\n",
    "\n",
    "# constraint 1:\n",
    "# one of ' riding a bike', ' ride bikes', ' rides a bike', ' biking', ' bikes' has to appear\n",
    "# AND one of ' park', ' beach' has to appear\n",
    "#keyphrases = [[' riding a bike', ' ride bikes', ' rides a bike', ' biking', ' bikes'],\n",
    "#            [' park', ' beach']]\n",
    "#for keyphrase in keyphrases:\n",
    "#    patterns = [tokenizer.encode(x) for x in keyphrase]\n",
    "#    dfa_graphs.append(ac_builder.build(patterns))\n",
    "\n",
    "# constraint 2: generate exactly 10 words\n",
    "# word_count_builder constructs a DFA representing the constraint that \n",
    "# the generated text must contain a to b words\n",
    "#a, b = 10, 10\n",
    "#dfa_graphs.append(word_count_builder.build(a, b))\n",
    "\n",
    "# taking the intersection of the DFAs, i.e., \"logical and\" of the constraints.\n",
    "# This function also minimizes the constructed DFA, which is mainly CPU-based operations;\n",
    "# Due to its pure python implemenation, DFA minimization can be slow for complex constraints\n",
    "#dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "\n",
    "# compile the dfa_graph for efficient GPU execution\n",
    "#dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "numbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "dfa_graph = {\n",
    "    \"edges\": [\n",
    "    (0, 1, ctrlg.populate_edge([\"Step\"], vocab_size, tokenizer)),\n",
    "    (1, 2, ctrlg.populate_edge([\"1)\"], vocab_size, tokenizer)),\n",
    "    (2, 3, ctrlg.populate_edge(letters, vocab_size, tokenizer)),\n",
    "    (3, 3, ctrlg.populate_edge(numbers, vocab_size, tokenizer)),\n",
    "    (3, 2, ctrlg.populate_edge([\"->\"], vocab_size, tokenizer)),\n",
    "    (3, 4, ctrlg.populate_edge([\"\",\".\",\",\",\";\"], vocab_size, tokenizer)),\n",
    "    (4, 5, ctrlg.populate_edge([\"Step\"], vocab_size, tokenizer)),\n",
    "    (5, 6, ctrlg.populate_edge([\"2)\"], vocab_size, tokenizer)),\n",
    "    (6, 7, ctrlg.populate_edge(['\"'], vocab_size, tokenizer)),\n",
    "    (7, 8, ctrlg.populate_edge(['marginal', 'conditional'], vocab_size, tokenizer)),\n",
    "    (8, 9, ctrlg.populate_edge(['probability'], vocab_size, tokenizer)),\n",
    "    (7, 11, ctrlg.populate_edge(['explaining'], vocab_size, tokenizer)),\n",
    "    (11, 12, ctrlg.populate_edge(['away'], vocab_size, tokenizer)),\n",
    "    (12, 9, ctrlg.populate_edge(['effect'], vocab_size, tokenizer)),\n",
    "    (7, 13, ctrlg.populate_edge(['backdoor'], vocab_size, tokenizer)),\n",
    "    (13, 14, ctrlg.populate_edge(['adjustment'], vocab_size, tokenizer)),\n",
    "    (14, 9, ctrlg.populate_edge(['set'], vocab_size, tokenizer)),\n",
    "    (7, 15, ctrlg.populate_edge(['average'], vocab_size, tokenizer)),\n",
    "    (15, 12, ctrlg.populate_edge(['treatment'], vocab_size, tokenizer)),\n",
    "    (7, 16, ctrlg.populate_edge(['collider'], vocab_size, tokenizer)),\n",
    "    (16, 9, ctrlg.populate_edge(['bias'], vocab_size, tokenizer)),\n",
    "    (7, 17, ctrlg.populate_edge(['normal'], vocab_size, tokenizer)),\n",
    "    (17, 18, ctrlg.populate_edge(['counterfactual'], vocab_size, tokenizer)),\n",
    "    (18, 9, ctrlg.populate_edge(['question'], vocab_size, tokenizer)),\n",
    "    (7, 19, ctrlg.populate_edge(['average'], vocab_size, tokenizer)),\n",
    "    (19, 20, ctrlg.populate_edge(['treatment'], vocab_size, tokenizer)),\n",
    "    (20, 21, ctrlg.populate_edge(['effect'], vocab_size, tokenizer)),\n",
    "    (21, 22, ctrlg.populate_edge(['on'], vocab_size, tokenizer)),\n",
    "    (22, 9, ctrlg.populate_edge(['treated'], vocab_size, tokenizer)),\n",
    "    (7, 23, ctrlg.populate_edge(['natural'], vocab_size, tokenizer)),\n",
    "    (23, 12, ctrlg.populate_edge(['direct','indirect'], vocab_size, tokenizer)),\n",
    "    (9, 10, ctrlg.populate_edge(['\"'], vocab_size, tokenizer)),\n",
    "    (10, 24, ctrlg.populate_edge([\"Step\"], vocab_size, tokenizer)),\n",
    "    (24, 25, ctrlg.populate_edge([\"3)\"], vocab_size, tokenizer)),\n",
    "    (25, 25, ctrlg.populate_edge(vocab_size=vocab_size, ALL=True)),\n",
    "    (25, 26, ctrlg.populate_edge([\"E\",\"P\"], vocab_size, tokenizer)),\n",
    "    (26, 27, ctrlg.populate_edge([\"(\",\"[\"], vocab_size, tokenizer)),\n",
    "    (27, 28, ctrlg.populate_edge(letters, vocab_size, tokenizer)),\n",
    "    (28, 29, ctrlg.populate_edge(numbers+[\"\"], vocab_size, tokenizer)),\n",
    "    (29, 27, ctrlg.populate_edge([\",\",\", \"], vocab_size, tokenizer)),\n",
    "    (29, 30, ctrlg.populate_edge([\"|\"], vocab_size, tokenizer)),\n",
    "    (30, 31, ctrlg.populate_edge(letters, vocab_size, tokenizer)),\n",
    "    (31, 32, ctrlg.populate_edge(numbers+[\"\"], vocab_size, tokenizer)),\n",
    "    (32, 30, ctrlg.populate_edge([\",\",\", \"], vocab_size, tokenizer)),\n",
    "    (32, 33, ctrlg.populate_edge([\")\"], vocab_size, tokenizer)),\n",
    "    (29, 33, ctrlg.populate_edge([\")\"], vocab_size, tokenizer)),\n",
    "    (29, 34, ctrlg.populate_edge([\"do\"], vocab_size, tokenizer)),\n",
    "    (34, 35, ctrlg.populate_edge([\"(\"], vocab_size, tokenizer)),\n",
    "    (35, 36, ctrlg.populate_edge(letters, vocab_size, tokenizer)),\n",
    "    (36, 37, ctrlg.populate_edge(numbers+[\"\"], vocab_size, tokenizer)),\n",
    "    (37, 38, ctrlg.populate_edge([\"=\"], vocab_size, tokenizer)),\n",
    "    (38, 39, ctrlg.populate_edge([\"0\",\"1\"], vocab_size, tokenizer)),\n",
    "    (39, 40, ctrlg.populate_edge([\")\"], vocab_size, tokenizer)),\n",
    "    (40, 41, ctrlg.populate_edge([\",\"], vocab_size, tokenizer)),\n",
    "    (41, 42, ctrlg.populate_edge([\"do\"], vocab_size, tokenizer)),\n",
    "    (42, 35, ctrlg.populate_edge([\"(\"], vocab_size, tokenizer)),\n",
    "    (39, 35, ctrlg.populate_edge([\",\"], vocab_size, tokenizer)),\n",
    "    (42, 37, ctrlg.populate_edge([\")\"], vocab_size, tokenizer)),\n",
    "    (37, 43, ctrlg.populate_edge([\"]\",\"\"], vocab_size, tokenizer)),\n",
    "    (43, 29, ctrlg.populate_edge([\".\", \"+\", \"-\", \"*\", \"/\", \"\"], vocab_size, tokenizer)),\n",
    "    ],\n",
    "    \"initial_state\": 0,\n",
    "    \"accept_states\": set([43]),\n",
    "}\n",
    "\n",
    "#dfa_graphs.append(dfa_graph1)\n",
    "#dfa_graphs.append(dfa_graph2)\n",
    "\n",
    "#dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='concatenation')\n",
    "\n",
    "# compile the dfa_graph for efficient GPU execution\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "##################################### DFA Construction #####################################\n",
    "\n",
    "\n",
    "##################################### token length #####################################\n",
    "# specify the min_new_tokens and max_new_tokens to be generated (excluding\n",
    "# the prefix and suffix) make sure that the numbers here would not conflict\n",
    "# with the given constraint: e.g. ask the model to generate 10 words with\n",
    "# max_new_tokens = 8\n",
    "min_new_tokens = 5\n",
    "max_new_tokens = 100\n",
    "##################################### token length #####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. generate with constraints.**\n",
    "\n",
    "Due to the use of @torch.compile, the first run of the following functions could be significantly slower than the later runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# initialze the constraints logits processor\n",
    "# Note: this part pre-computes & cache certain conditional probability tables;\n",
    "# one simple optimization is to re-use the same constraint_logits_processor for\n",
    "# base_model.generate if the constraints do not change.\n",
    "constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "    hmm_model, dfa_model,\n",
    "    min_new_tokens, max_new_tokens,\n",
    "    prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "# set beam_size for beam search; usually the larger the beam_size the\n",
    "# higher the generation quality\n",
    "beam_size = 64\n",
    "\n",
    "# set the hmm_batch_size depending on the resource available;\n",
    "# uses more memory with larger hmm_batch_size but attains best speed \n",
    "# when it is set to beam_size\n",
    "constraint_logits_processor.hmm_batch_size = beam_size\n",
    "\n",
    "# generate with beam search\n",
    "input_ids = torch.tensor([prompt_ids], device=device)\n",
    "outputs = base_model.generate(\n",
    "        input_ids=input_ids, do_sample=False, length_penalty=0.2,\n",
    "        num_beams=beam_size, num_return_sequences=beam_size,\n",
    "        min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "        logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. extract & rank outputs via the base model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 319]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Chapter]\n",
      "\n",
      "Transmigrator Meets Reincarnator\n",
      "\n",
      "Chapter -> X \u001b[0m\n",
      "1. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1mThe X        BACK ->\u001b[0m\n",
      "2. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1mThe X        Next ->\u001b[0m\n",
      "3. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Part]\n",
      "\n",
      "My Wife is a Beautiful CEO\n",
      "\n",
      "Chapter 153-1: X ・ ->\u001b[0m\n",
      "4. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Part]\n",
      "\n",
      "My Wife is a Beautiful CEO\n",
      "\n",
      "Chapter 123-1: X ~~ ->\u001b[0m\n",
      "5. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Part]\n",
      "\n",
      "My Wife is a Beautiful CEO\n",
      "\n",
      "Chapter 123-1: X ・ ->\u001b[0m\n",
      "6. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Part]\n",
      "\n",
      "My Wife is a Beautiful CEO\n",
      "\n",
      "Chapter 123-1: X  ->\u001b[0m\n",
      "7. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Part]\n",
      "\n",
      "My Wife is a Beautiful CEO\n",
      "\n",
      "Chapter 153-1: X  ->\u001b[0m\n",
      "8. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Chapter]\n",
      "\n",
      "Transmigrator Meets Reincarnator\n",
      "\n",
      "Chapter 103: X ~~ ->\u001b[0m\n",
      "9. The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\u001b[1m[Previous Chapter] [Table of Contents] [Next Chapter]\n",
      "\n",
      "Transmigrator Meets Reincarnator\n",
      "\n",
      "Chapter 97: X  ->\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "# rank the generated ids by the base_model probability\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "# print top 10 outputs\n",
    "for idx, generated in enumerate(generated_ids[:10]):\n",
    "    print(f'{idx}. ' + tokenizer.decode(prefix_ids, skip_special_tokens=True) + \\\n",
    "          '\\033[1m' + tokenizer.decode(generated, skip_special_tokens=True) + '\\033[0m' + \\\n",
    "          tokenizer.decode(suffix_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5. try some other constraints! (example constraint 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  on a fine sunny\u001b[1m day a young girl is walking her dog\u001b[0m in the park.\n",
      "1.  on a fine sunny\u001b[1m day a young boy and his dog are playing\u001b[0m in the park.\n",
      "2.  on a fine sunny\u001b[1m day a young boy is playing with his dog\u001b[0m in the park.\n",
      "3.  on a fine sunny\u001b[1m day a boy and his dog are playing\u001b[0m in the park.\n",
      "4.  on a fine sunny\u001b[1m day a young boy and his dog are walking\u001b[0m in the park.\n",
      "5.  on a fine sunny\u001b[1m day a young girl and her dog are playing\u001b[0m in the park.\n",
      "6.  on a fine sunny\u001b[1m day a young girl and her dog are walking\u001b[0m in the park.\n",
      "7.  on a fine sunny\u001b[1m day a young girl is playing with her dog\u001b[0m in the park.\n",
      "8.  on a fine sunny\u001b[1m day a girl is walking her dog\u001b[0m in the park.\n",
      "9.  on a fine sunny\u001b[1m day a young boy and his dog are relaxing\u001b[0m in the park.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "\n",
    "prefix = ' on a fine sunny' # generate text starting with ' on a fine sunny'\n",
    "suffix = ' in the park.<|endoftext|>' # generate text ending with ' in the park.<|endoftext|>'\n",
    "prompt = '<|endoftext|> on a fine sunny' # prompt the base model with the '<|endoftext|>' token and the prefix\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)\n",
    "suffix_ids = tokenizer.encode(suffix)\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "\n",
    "ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "word_count_builder = ctrlg.WordCountBuilder(tokenizer, vocab_size)\n",
    "\n",
    "dfa_graphs = []\n",
    "# constraint 1:\n",
    "# one of ' girl', ' boy', ' girls', ' boys', ' children' AND\n",
    "# one of ' dogs', ' cats', ' dog', ' cat' have to appear\n",
    "# in the GIVEN ORDER.\n",
    "\n",
    "keyphrases = [[' girl', ' boy', ' girls', ' boys', ' children'],\n",
    "            [' dogs', ' cats', ' dog', ' cat']]\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x) for x in keyphrase]\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "# concatenate the patterns so they appear in the given order\n",
    "dfa_graphs = [ctrlg.DFA_concatenate(dfa_graphs)]\n",
    "\n",
    "# constraint 2: generate 7 - 12 words\n",
    "a, b = 7, 12\n",
    "dfa_graphs.append(word_count_builder.build(a, b))\n",
    "\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "\n",
    "min_new_tokens = 5\n",
    "max_new_tokens = 32\n",
    "\n",
    "\n",
    "# initialze the constraints logits processor\n",
    "constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "    hmm_model, dfa_model,\n",
    "    min_new_tokens, max_new_tokens,\n",
    "    prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "beam_size = 128\n",
    "constraint_logits_processor.hmm_batch_size = beam_size\n",
    "input_ids = torch.tensor([prompt_ids], device=device)\n",
    "# generate with beam search\n",
    "outputs = base_model.generate(\n",
    "        input_ids=input_ids, do_sample=False,\n",
    "        num_beams=beam_size, num_return_sequences=beam_size,\n",
    "        min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "        logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "# extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "# rank the generated ids by the base_model probability\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "# print top 10 outputs\n",
    "for idx, generated in enumerate(generated_ids[:10]):\n",
    "    print(f'{idx}. ' + tokenizer.decode(prefix_ids, skip_special_tokens=True) + \\\n",
    "          '\\033[1m' + tokenizer.decode(generated, skip_special_tokens=True) + '\\033[0m' + \\\n",
    "          tokenizer.decode(suffix_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part B**. Ctrl-G on TULU2-7B (more computation required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. load pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Downloading protobuf-5.28.0-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-5.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bazaluk/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006e75dc3fe544b980482534b21aa4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bazaluk/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # set your cuda device\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "import ctrlg\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "# load the pretrained base_model and hmm_model;\n",
    "BASE_MODEL_PATH = f'ctrlg/tulu2-7b_writing-prompts'\n",
    "HMM_MODEL_PATH = f'ctrlg/hmm_tulu2-7b_writing-prompts_32768'\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH).to(device)\n",
    "base_model.eval()\n",
    "base_model.half() # fp16 inference\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "hmm_model = ctrlg.HMM.from_pretrained(HMM_MODEL_PATH).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. specify logical constraints as DFAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORIGINAL VERSION ##\n",
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id #eos = end of sentence\n",
    "\n",
    "prefix = 'Once upon a time, in a land far, far away, there was a kingdom. The kingdom was'\n",
    "suffix = 'beautiful buildings. The people of this kingdom were known for their kindness and generosity, always ready to lend a helping hand.</s>'\n",
    "soft_constraint = ' in fairytale style' # use empty string for no soft constraint\n",
    "prompt = f'<|user|>\\nContinue the given text{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)[1:]\n",
    "suffix_ids = tokenizer.encode(suffix)[1:]\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "eos_builder = ctrlg.EOSBuilder(vocab_size, eos_token_id)\n",
    "\n",
    "dfa_graphs = []\n",
    "keyphrases = [['towering'], ['reach the sky'], ['reflected'], ['lake']]\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x)[1:] for x in keyphrase]\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "dfa_graphs.append(eos_builder.build())\n",
    "\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "min_new_tokens = 16\n",
    "max_new_tokens = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/media/data/bazaluk/ctrlg_tulu2/data.csv')\n",
    "data['pred_graphs'] = ''\n",
    "\n",
    "## MY VERSION ##\n",
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "#prefix = \"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\"\n",
    "#suffix = '</s>'\n",
    "#soft_constraint = '' # use empty string for no soft constraint\n",
    "#prompt = f'<|user|>\\n\"Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.<|endoftext|>\"{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "prefix = data['prefix'].iloc[2000]\n",
    "d_prompt = data['prompt'].iloc[2000]\n",
    "suffix = '</s>'\n",
    "soft_constraint = '' # use empty string for no soft constraint\n",
    "prompt = f'<|user|>\\n\"{d_prompt}<|endoftext|>\"{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)[1:]\n",
    "suffix_ids = tokenizer.encode(suffix)[1:]\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "#ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "ac_builder = ctrlg.NewAhoCorasickBuilder(vocab_size)\n",
    "eos_builder = ctrlg.EOSBuilder(vocab_size, eos_token_id)\n",
    "trivial = ctrlg.TrivialBuilder(vocab_size, eos_token_id)\n",
    "\n",
    "dfa_graphs = []\n",
    "#keyphrases = [['towering'], ['reach the sky'], ['reflected'], ['lake']]\n",
    "keyphrases = [[' X ', ' Y ', ' V2 ', ' V3 ', ' V4 ', ' V5 '],\n",
    "                [' ->'],\n",
    "                 [' X ', ' Y ', ' V2 ', ' V3 ', ' V4 ', ' V5 ']\n",
    "             ]\n",
    "\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x)[1:] for x in keyphrase]\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "dfa_graphs.append(eos_builder.build())\n",
    "\n",
    "\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "\n",
    "#######################################\n",
    "#qd faz o grafo na mao eu acho q ele mistura os tokens q tao na lista - tem q conferir\n",
    "\n",
    "dfa_graph = {\n",
    "    \"edges\": [\n",
    "    (0, 2, ctrlg.populate_edge(['X', 'Y'], vocab_size, tokenizer)),\n",
    "    (0, 1, ctrlg.populate_edge(['V'], vocab_size, tokenizer)),\n",
    "    (1, 2, ctrlg.populate_edge(['1', '2', '3', '4', '5'], vocab_size, tokenizer)),\n",
    "    (2, 3, ctrlg.populate_edge(['->'], vocab_size, tokenizer)),\n",
    "    (3, 4, ctrlg.populate_edge(['V'], vocab_size, tokenizer)),\n",
    "    (3, 5, ctrlg.populate_edge(['X','Y'], vocab_size, tokenizer)),\n",
    "    (4, 5, ctrlg.populate_edge(['1', '2', '3', '4', '5'], vocab_size, tokenizer)),\n",
    "    (5, 0, ctrlg.populate_edge([','], vocab_size, tokenizer)),\n",
    "    ],\n",
    "    \"initial_state\": 0,\n",
    "    \"accept_states\": set([5]),\n",
    "}\n",
    "########################################\n",
    "\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "min_new_tokens = 1\n",
    "max_new_tokens = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/media/data/bazaluk/ctrlg_tulu2/data.csv')\n",
    "data['pred_graphs'] = ''\n",
    "\n",
    "## MY VERSION ##\n",
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "#prefix = \"The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in 'var1 -> var2' format, separated by commas:\"\n",
    "#suffix = '</s>'\n",
    "#soft_constraint = '' # use empty string for no soft constraint\n",
    "#prompt = f'<|user|>\\n\"Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.<|endoftext|>\"{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "prefix = data['prefix'].iloc[2000]\n",
    "d_prompt = data['prompt'].iloc[2000]\n",
    "suffix = '</s>'\n",
    "soft_constraint = '' # use empty string for no soft constraint\n",
    "prompt = f'<|user|>\\n\"{d_prompt}<|endoftext|>\"{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)[1:]\n",
    "suffix_ids = tokenizer.encode(suffix)[1:]\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "#ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "ac_builder = ctrlg.NewAhoCorasickBuilder(vocab_size)\n",
    "eos_builder = ctrlg.EOSBuilder(vocab_size, eos_token_id)\n",
    "trivial = ctrlg.TrivialBuilder(tokenizer,vocab_size, eos_token_id)\n",
    "\n",
    "dfa_graph = trivial.build()\n",
    "\n",
    "\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "min_new_tokens = 1\n",
    "max_new_tokens = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1919]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. generate with constraints.\n",
    "\n",
    "Due to the use of @torch.compile, the first run of the following functions could be significantly slower than the later runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. V1 -> X\n",
      "1. V1 -> X\n",
      "2. V1 -> X\n",
      "3. V1 -> X\n",
      "4. V1 -> X\n"
     ]
    }
   ],
   "source": [
    "dic = {} #the keys are the temperatures and the values are a list of the 10 predicted graphs\n",
    "temp = [1,10,50,100]\n",
    "\n",
    "# initialze the constraints logits processor\n",
    "constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "    hmm_model, dfa_model,\n",
    "    min_new_tokens, max_new_tokens,\n",
    "    prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "# set the hmm_batch_size & temperature\n",
    "beam_size = 32 # sample 128 sequences\n",
    "temperature = 0.7\n",
    "constraint_logits_processor.hmm_batch_size = beam_size\n",
    "constraint_logits_processor.temperature = temperature\n",
    "\n",
    "\n",
    "\n",
    "# generate with sampling, temperature=0.7\n",
    "input_ids = torch.tensor([prompt_ids], device=device)\n",
    "outputs = base_model.generate(\n",
    "        input_ids=input_ids, do_sample=True,\n",
    "        num_return_sequences=beam_size, \n",
    "        min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "        logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "\n",
    "# extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "# filter 75% of the generated ids by how well they connect with the suffix\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids,\n",
    "                                            suffix_logits_only=True, suffix_length_cap=5)[:32]\n",
    "# rank the generated ids by the base_model for higher quality\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "dic[temperature] = []\n",
    "# print top 10 outputs\n",
    "for idx, generated in enumerate(generated_ids[:5]):\n",
    "    print(f'{idx}. ' + tokenizer.decode(generated, skip_special_tokens=True) + \\\n",
    "          tokenizer.decode(suffix_ids, skip_special_tokens=True))\n",
    "    #dic[temperature].append(tokenizer.decode(generated, skip_special_tokens=True) + \\\n",
    "    #      tokenizer.decode(suffix_ids, skip_special_tokens=True))\n",
    "    #print(f'{idx}. ' + tokenizer.decode(prefix_ids, skip_special_tokens=True) + \\\n",
    "    #      ' ' + '\\033[1m' + tokenizer.decode(generated, skip_special_tokens=True) + '\\033[0m' + ' ' + \\\n",
    "    #      tokenizer.decode(suffix_ids, skip_special_tokens=True))\n",
    "\n",
    "#data.at[i, 'pred_graphs'] = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1001\n",
       "prompt                                                                                                                                                             Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V1 to represent gender. Use X to represent smoking. Use V3 to represent tar deposit. Use Y to represent lung cancer. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.\n",
       "prefix         The overall probability of smoking is 52%. The probability of nonsmoking and lung cancer is 16%. The probability of smoking and lung cancer is 26%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V1 to represent gender. Use X to represent smoking. Use V3 to represent tar deposit. Use Y to represent lung cancer. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:\n",
       "step1                                                                                                                                                                                                                                                                                                                                                                                                                                                                     V1->X,X->V3,V1->Y,V3->Y\n",
       "pred_graphs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "Name: 1001, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data.iloc[1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [2, 3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {}\n",
    "a['x']=[]\n",
    "a['x'].append(2)\n",
    "a['x'].append(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at['linha', 'col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>desc_id</th>\n",
       "      <th>given_info</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>meta</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>step0</th>\n",
       "      <th>step1</th>\n",
       "      <th>step2</th>\n",
       "      <th>step3</th>\n",
       "      <th>step4</th>\n",
       "      <th>step5</th>\n",
       "      <th>step6</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>alarm-mediation-nde-model0-spec0-q0</td>\n",
       "      <td>For husbands that don't set the alarm and wive...</td>\n",
       "      <td>If we disregard the mediation effect through w...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'story_id': 'alarm', 'graph_id': 'mediation',...</td>\n",
       "      <td>{'step0': 'Let X = husband; V2 = wife; Y = ala...</td>\n",
       "      <td>Let X = husband; V2 = wife; Y = alarm clock.</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>nde</td>\n",
       "      <td>E[Y_{X=1, V2=0} - Y_{X=0, V2=0}]</td>\n",
       "      <td>P(Y=1 | X=0, V2=0) = 0.08\\nP(Y=1 | X=0, V2=1) ...</td>\n",
       "      <td>\\sum_{V2=v} P(V2=v|X=0)*[P(Y=1|X=1,V2=v) - P(Y...</td>\n",
       "      <td>0.74 * (0.86 - 0.41) + 0.24 * (0.54 - 0.08) = ...</td>\n",
       "      <td>0.32 &gt; 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>alarm-mediation-ate-model1-spec1-q1</td>\n",
       "      <td>For husbands that don't set the alarm, the pro...</td>\n",
       "      <td>Will alarm set by husband decrease the chance ...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'story_id': 'alarm', 'graph_id': 'mediation',...</td>\n",
       "      <td>{'step0': 'Let X = husband; V2 = wife; Y = ala...</td>\n",
       "      <td>Let X = husband; V2 = wife; Y = alarm clock.</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>ate</td>\n",
       "      <td>E[Y | do(X = 1)] - E[Y | do(X = 0)]</td>\n",
       "      <td>P(Y=1 | X=0) = 0.26\\nP(Y=1 | X=1) = 0.76</td>\n",
       "      <td>P(Y=1|X=1) - P(Y=1|X=0)</td>\n",
       "      <td>0.76 - 0.26 = 0.50</td>\n",
       "      <td>0.50 &gt; 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>alarm-mediation-marginal-model1-spec1-q0</td>\n",
       "      <td>The overall probability of alarm set by husban...</td>\n",
       "      <td>Is ringing alarm more likely than silent alarm...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'story_id': 'alarm', 'graph_id': 'mediation',...</td>\n",
       "      <td>{'step0': 'Let X = husband; V2 = wife; Y = ala...</td>\n",
       "      <td>Let X = husband; V2 = wife; Y = alarm clock.</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>marginal</td>\n",
       "      <td>P(Y)</td>\n",
       "      <td>P(X=1) = 0.77\\nP(Y=1 | X=0) = 0.26\\nP(Y=1 | X=...</td>\n",
       "      <td>P(Y | X=1)*P(X=1) + P(Y | X=0)*P(X=0)</td>\n",
       "      <td>0.77*0.76 - 0.23*0.26 = 0.64</td>\n",
       "      <td>0.64 &gt; 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>alarm-mediation-ate-model3-spec3-q1</td>\n",
       "      <td>For husbands that don't set the alarm, the pro...</td>\n",
       "      <td>Will alarm set by husband decrease the chance ...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'story_id': 'alarm', 'graph_id': 'mediation',...</td>\n",
       "      <td>{'step0': 'Let X = husband; V2 = wife; Y = ala...</td>\n",
       "      <td>Let X = husband; V2 = wife; Y = alarm clock.</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>ate</td>\n",
       "      <td>E[Y | do(X = 1)] - E[Y | do(X = 0)]</td>\n",
       "      <td>P(Y=1 | X=0) = 0.20\\nP(Y=1 | X=1) = 0.68</td>\n",
       "      <td>P(Y=1|X=1) - P(Y=1|X=0)</td>\n",
       "      <td>0.68 - 0.20 = 0.49</td>\n",
       "      <td>0.49 &gt; 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>alarm-mediation-nie-model4-spec4-q0</td>\n",
       "      <td>For husbands that don't set the alarm and wive...</td>\n",
       "      <td>Does husband positively affect alarm clock thr...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'story_id': 'alarm', 'graph_id': 'mediation',...</td>\n",
       "      <td>{'step0': 'Let X = husband; V2 = wife; Y = ala...</td>\n",
       "      <td>Let X = husband; V2 = wife; Y = alarm clock.</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>nie</td>\n",
       "      <td>E[Y_{X=0, V2=1} - Y_{X=0, V2=0}]</td>\n",
       "      <td>P(Y=1 | X=0, V2=0) = 0.11\\nP(Y=1 | X=0, V2=1) ...</td>\n",
       "      <td>\\sum_{V2 = v} P(Y=1|X =0,V2 = v)*[P(V2 = v | X...</td>\n",
       "      <td>0.01 * (0.60 - 0.11)+ 0.61 * (0.92 - 0.46)= -0.29</td>\n",
       "      <td>-0.29 &lt; 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>31012</td>\n",
       "      <td>nonsense9-fork-det-counterfactual-model3842-sp...</td>\n",
       "      <td>We know that zuph or jyka causes glimx. We obs...</td>\n",
       "      <td>Would an individual is glimx if not zuph inste...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'story_id': 'nonsense9', 'graph_id': 'fork', ...</td>\n",
       "      <td>{'step0': 'Let V2 = jyka; X = zuph; Y = glimx....</td>\n",
       "      <td>Let V2 = jyka; X = zuph; Y = glimx.</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>det-counterfactual</td>\n",
       "      <td>Y_{X=0} = 1 | V2=1</td>\n",
       "      <td>V2 = 1\\nY = X or V2</td>\n",
       "      <td>Solve for Y, given the evidence and the action</td>\n",
       "      <td>Y = 1 = 0 or 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>31014</td>\n",
       "      <td>nonsense9-fork-det-counterfactual-model3842-sp...</td>\n",
       "      <td>We know that zuph or jyka causes glimx. We obs...</td>\n",
       "      <td>Would an individual is glimx if zuph instead o...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'story_id': 'nonsense9', 'graph_id': 'fork', ...</td>\n",
       "      <td>{'step0': 'Let V2 = jyka; X = zuph; Y = glimx....</td>\n",
       "      <td>Let V2 = jyka; X = zuph; Y = glimx.</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>det-counterfactual</td>\n",
       "      <td>Y_{X=1} = 1 | V2=1</td>\n",
       "      <td>V2 = 1\\nY = X or V2</td>\n",
       "      <td>Solve for Y, given the evidence and the action</td>\n",
       "      <td>Y = 1 = 1 or 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>31015</td>\n",
       "      <td>nonsense9-fork-det-counterfactual-model3842-sp...</td>\n",
       "      <td>We know that zuph or jyka causes glimx. We obs...</td>\n",
       "      <td>Would an individual is not glimx if zuph inste...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'story_id': 'nonsense9', 'graph_id': 'fork', ...</td>\n",
       "      <td>{'step0': 'Let V2 = jyka; X = zuph; Y = glimx....</td>\n",
       "      <td>Let V2 = jyka; X = zuph; Y = glimx.</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>det-counterfactual</td>\n",
       "      <td>Y_{X=1} = 0 | V2=1</td>\n",
       "      <td>V2 = 1\\nY = X or V2</td>\n",
       "      <td>Solve for Y, given the evidence and the action</td>\n",
       "      <td>Y = 1 = 1 or 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>31016</td>\n",
       "      <td>nonsense9-fork-det-counterfactual-model3843-sp...</td>\n",
       "      <td>We know that zuph and jyka causes glimx. We ob...</td>\n",
       "      <td>Would an individual is glimx if not zuph inste...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'story_id': 'nonsense9', 'graph_id': 'fork', ...</td>\n",
       "      <td>{'step0': 'Let V2 = jyka; X = zuph; Y = glimx....</td>\n",
       "      <td>Let V2 = jyka; X = zuph; Y = glimx.</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>det-counterfactual</td>\n",
       "      <td>Y_{X=0} = 1 | V2=0</td>\n",
       "      <td>V2 = 0\\nY = X and V2</td>\n",
       "      <td>Solve for Y, given the evidence and the action</td>\n",
       "      <td>Y = 0 = 0 and 0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>31019</td>\n",
       "      <td>nonsense9-fork-det-counterfactual-model3843-sp...</td>\n",
       "      <td>We know that zuph and jyka causes glimx. We ob...</td>\n",
       "      <td>Would an individual is not glimx if zuph inste...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'story_id': 'nonsense9', 'graph_id': 'fork', ...</td>\n",
       "      <td>{'step0': 'Let V2 = jyka; X = zuph; Y = glimx....</td>\n",
       "      <td>Let V2 = jyka; X = zuph; Y = glimx.</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>det-counterfactual</td>\n",
       "      <td>Y_{X=1} = 0 | V2=0</td>\n",
       "      <td>V2 = 0\\nY = X and V2</td>\n",
       "      <td>Solve for Y, given the evidence and the action</td>\n",
       "      <td>Y = 0 = 1 and 0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8532 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                                            desc_id  \\\n",
       "0               4                alarm-mediation-nde-model0-spec0-q0   \n",
       "1               7                alarm-mediation-ate-model1-spec1-q1   \n",
       "2               8           alarm-mediation-marginal-model1-spec1-q0   \n",
       "3              15                alarm-mediation-ate-model3-spec3-q1   \n",
       "4              21                alarm-mediation-nie-model4-spec4-q0   \n",
       "...           ...                                                ...   \n",
       "8527        31012  nonsense9-fork-det-counterfactual-model3842-sp...   \n",
       "8528        31014  nonsense9-fork-det-counterfactual-model3842-sp...   \n",
       "8529        31015  nonsense9-fork-det-counterfactual-model3842-sp...   \n",
       "8530        31016  nonsense9-fork-det-counterfactual-model3843-sp...   \n",
       "8531        31019  nonsense9-fork-det-counterfactual-model3843-sp...   \n",
       "\n",
       "                                             given_info  \\\n",
       "0     For husbands that don't set the alarm and wive...   \n",
       "1     For husbands that don't set the alarm, the pro...   \n",
       "2     The overall probability of alarm set by husban...   \n",
       "3     For husbands that don't set the alarm, the pro...   \n",
       "4     For husbands that don't set the alarm and wive...   \n",
       "...                                                 ...   \n",
       "8527  We know that zuph or jyka causes glimx. We obs...   \n",
       "8528  We know that zuph or jyka causes glimx. We obs...   \n",
       "8529  We know that zuph or jyka causes glimx. We obs...   \n",
       "8530  We know that zuph and jyka causes glimx. We ob...   \n",
       "8531  We know that zuph and jyka causes glimx. We ob...   \n",
       "\n",
       "                                               question answer  \\\n",
       "0     If we disregard the mediation effect through w...    yes   \n",
       "1     Will alarm set by husband decrease the chance ...     no   \n",
       "2     Is ringing alarm more likely than silent alarm...    yes   \n",
       "3     Will alarm set by husband decrease the chance ...     no   \n",
       "4     Does husband positively affect alarm clock thr...     no   \n",
       "...                                                 ...    ...   \n",
       "8527  Would an individual is glimx if not zuph inste...    yes   \n",
       "8528  Would an individual is glimx if zuph instead o...    yes   \n",
       "8529  Would an individual is not glimx if zuph inste...     no   \n",
       "8530  Would an individual is glimx if not zuph inste...     no   \n",
       "8531  Would an individual is not glimx if zuph inste...    yes   \n",
       "\n",
       "                                                   meta  \\\n",
       "0     {'story_id': 'alarm', 'graph_id': 'mediation',...   \n",
       "1     {'story_id': 'alarm', 'graph_id': 'mediation',...   \n",
       "2     {'story_id': 'alarm', 'graph_id': 'mediation',...   \n",
       "3     {'story_id': 'alarm', 'graph_id': 'mediation',...   \n",
       "4     {'story_id': 'alarm', 'graph_id': 'mediation',...   \n",
       "...                                                 ...   \n",
       "8527  {'story_id': 'nonsense9', 'graph_id': 'fork', ...   \n",
       "8528  {'story_id': 'nonsense9', 'graph_id': 'fork', ...   \n",
       "8529  {'story_id': 'nonsense9', 'graph_id': 'fork', ...   \n",
       "8530  {'story_id': 'nonsense9', 'graph_id': 'fork', ...   \n",
       "8531  {'story_id': 'nonsense9', 'graph_id': 'fork', ...   \n",
       "\n",
       "                                              reasoning  \\\n",
       "0     {'step0': 'Let X = husband; V2 = wife; Y = ala...   \n",
       "1     {'step0': 'Let X = husband; V2 = wife; Y = ala...   \n",
       "2     {'step0': 'Let X = husband; V2 = wife; Y = ala...   \n",
       "3     {'step0': 'Let X = husband; V2 = wife; Y = ala...   \n",
       "4     {'step0': 'Let X = husband; V2 = wife; Y = ala...   \n",
       "...                                                 ...   \n",
       "8527  {'step0': 'Let V2 = jyka; X = zuph; Y = glimx....   \n",
       "8528  {'step0': 'Let V2 = jyka; X = zuph; Y = glimx....   \n",
       "8529  {'step0': 'Let V2 = jyka; X = zuph; Y = glimx....   \n",
       "8530  {'step0': 'Let V2 = jyka; X = zuph; Y = glimx....   \n",
       "8531  {'step0': 'Let V2 = jyka; X = zuph; Y = glimx....   \n",
       "\n",
       "                                             step0             step1  \\\n",
       "0     Let X = husband; V2 = wife; Y = alarm clock.  X->V2,X->Y,V2->Y   \n",
       "1     Let X = husband; V2 = wife; Y = alarm clock.  X->V2,X->Y,V2->Y   \n",
       "2     Let X = husband; V2 = wife; Y = alarm clock.  X->V2,X->Y,V2->Y   \n",
       "3     Let X = husband; V2 = wife; Y = alarm clock.  X->V2,X->Y,V2->Y   \n",
       "4     Let X = husband; V2 = wife; Y = alarm clock.  X->V2,X->Y,V2->Y   \n",
       "...                                            ...               ...   \n",
       "8527           Let V2 = jyka; X = zuph; Y = glimx.        X->Y,V2->Y   \n",
       "8528           Let V2 = jyka; X = zuph; Y = glimx.        X->Y,V2->Y   \n",
       "8529           Let V2 = jyka; X = zuph; Y = glimx.        X->Y,V2->Y   \n",
       "8530           Let V2 = jyka; X = zuph; Y = glimx.        X->Y,V2->Y   \n",
       "8531           Let V2 = jyka; X = zuph; Y = glimx.        X->Y,V2->Y   \n",
       "\n",
       "                   step2                                step3  \\\n",
       "0                    nde     E[Y_{X=1, V2=0} - Y_{X=0, V2=0}]   \n",
       "1                    ate  E[Y | do(X = 1)] - E[Y | do(X = 0)]   \n",
       "2               marginal                                 P(Y)   \n",
       "3                    ate  E[Y | do(X = 1)] - E[Y | do(X = 0)]   \n",
       "4                    nie     E[Y_{X=0, V2=1} - Y_{X=0, V2=0}]   \n",
       "...                  ...                                  ...   \n",
       "8527  det-counterfactual                   Y_{X=0} = 1 | V2=1   \n",
       "8528  det-counterfactual                   Y_{X=1} = 1 | V2=1   \n",
       "8529  det-counterfactual                   Y_{X=1} = 0 | V2=1   \n",
       "8530  det-counterfactual                   Y_{X=0} = 1 | V2=0   \n",
       "8531  det-counterfactual                   Y_{X=1} = 0 | V2=0   \n",
       "\n",
       "                                                  step4  \\\n",
       "0     P(Y=1 | X=0, V2=0) = 0.08\\nP(Y=1 | X=0, V2=1) ...   \n",
       "1              P(Y=1 | X=0) = 0.26\\nP(Y=1 | X=1) = 0.76   \n",
       "2     P(X=1) = 0.77\\nP(Y=1 | X=0) = 0.26\\nP(Y=1 | X=...   \n",
       "3              P(Y=1 | X=0) = 0.20\\nP(Y=1 | X=1) = 0.68   \n",
       "4     P(Y=1 | X=0, V2=0) = 0.11\\nP(Y=1 | X=0, V2=1) ...   \n",
       "...                                                 ...   \n",
       "8527                                V2 = 1\\nY = X or V2   \n",
       "8528                                V2 = 1\\nY = X or V2   \n",
       "8529                                V2 = 1\\nY = X or V2   \n",
       "8530                               V2 = 0\\nY = X and V2   \n",
       "8531                               V2 = 0\\nY = X and V2   \n",
       "\n",
       "                                                  step5  \\\n",
       "0     \\sum_{V2=v} P(V2=v|X=0)*[P(Y=1|X=1,V2=v) - P(Y...   \n",
       "1                               P(Y=1|X=1) - P(Y=1|X=0)   \n",
       "2                 P(Y | X=1)*P(X=1) + P(Y | X=0)*P(X=0)   \n",
       "3                               P(Y=1|X=1) - P(Y=1|X=0)   \n",
       "4     \\sum_{V2 = v} P(Y=1|X =0,V2 = v)*[P(V2 = v | X...   \n",
       "...                                                 ...   \n",
       "8527     Solve for Y, given the evidence and the action   \n",
       "8528     Solve for Y, given the evidence and the action   \n",
       "8529     Solve for Y, given the evidence and the action   \n",
       "8530     Solve for Y, given the evidence and the action   \n",
       "8531     Solve for Y, given the evidence and the action   \n",
       "\n",
       "                                                  step6        end  \n",
       "0     0.74 * (0.86 - 0.41) + 0.24 * (0.54 - 0.08) = ...   0.32 > 0  \n",
       "1                                    0.76 - 0.26 = 0.50   0.50 > 0  \n",
       "2                          0.77*0.76 - 0.23*0.26 = 0.64   0.64 > 0  \n",
       "3                                    0.68 - 0.20 = 0.49   0.49 > 0  \n",
       "4     0.01 * (0.60 - 0.11)+ 0.61 * (0.92 - 0.46)= -0.29  -0.29 < 0  \n",
       "...                                                 ...        ...  \n",
       "8527                                     Y = 1 = 0 or 1          1  \n",
       "8528                                     Y = 1 = 1 or 1          1  \n",
       "8529                                     Y = 1 = 1 or 1          0  \n",
       "8530                                    Y = 0 = 0 and 0          0  \n",
       "8531                                    Y = 0 = 1 and 0          1  \n",
       "\n",
       "[8532 rows x 15 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json('/home/bazaluk/master_project/cladder.json')\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "data = data.assign(step0 = lambda x: (x['reasoning']))\n",
    "df = data['step0'].apply(lambda x: (x.get(\"step0\")))\n",
    "data['step0'] = df\n",
    "\n",
    "data = data.assign(step1 = lambda x: (x['reasoning']))\n",
    "df = data['step1'].apply(lambda x: (x.get(\"step1\")))\n",
    "data['step1'] = df\n",
    "\n",
    "#step2) query type\n",
    "data = data.assign(step2 = lambda x: (x['meta']))\n",
    "df = data['step2'].apply(lambda x: (x.get(\"query_type\")))\n",
    "data['step2'] = df\n",
    "\n",
    "#step3) formalize query\n",
    "data = data.assign(step3 = lambda x: (x['reasoning']))\n",
    "df = data['step3'].apply(lambda x: (x.get(\"step2\")))\n",
    "data['step3'] = df\n",
    "\n",
    "#step4) extract all available data\n",
    "data = data.assign(step4 = lambda x: (x['reasoning']))\n",
    "df = data['step4'].apply(lambda x: (x.get(\"step4\")))\n",
    "data['step4'] = df\n",
    "\n",
    "#step5) deduce estimand\n",
    "data = data.assign(step5 = lambda x: (x['reasoning']))\n",
    "df = data['step5'].apply(lambda x: (x.get(\"step3\")))\n",
    "data['step5'] = df\n",
    "\n",
    "#step6)Insert the relevant data in Step 4 into the estimand, perform basic arithmetic calculations\n",
    "data = data.assign(step6 = lambda x: (x['reasoning']))\n",
    "df = data['step6'].apply(lambda x: (x.get(\"step5\")))\n",
    "data['step6'] = df\n",
    "\n",
    "#end) derive the final answer\n",
    "data = data.assign(end = lambda x: (x['reasoning']))\n",
    "df = data['end'].apply(lambda x: (x.get(\"end\")))\n",
    "data['end'] = df\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of real variable names and their respective representation e.g. [['X','wife'],['Y','husband']]\n",
    "def list_representation(x):\n",
    "    x = x.get('step0')\n",
    "    x = x[4:len(x)-1] #erase \"Let \" and the last \".\"\n",
    "    x = x.split('; ')\n",
    "\n",
    "    aux = []\n",
    "    for i in range(len(x)):\n",
    "        aux.append(x[i].split(\" = \"))\n",
    "    return aux\n",
    "\n",
    "#receives a list from list_representation and returns the prompt with it\n",
    "def prompt_repres(x):\n",
    "    x = x.get('step0')\n",
    "    x = x[4:len(x)-1] #erase \"Let \" and the last \".\"\n",
    "    x = x.split('; ')\n",
    "\n",
    "    list_rep = []\n",
    "    for i in range(len(x)):\n",
    "        list_rep.append(x[i].split(\" = \"))\n",
    "    \n",
    "    prompt = \"\"\n",
    "    for i in range(len(list_rep)):\n",
    "        prompt += \"Use \"+list_rep[i][0]+\" to represent \"+list_rep[i][1]+\". \"\n",
    "    return prompt\n",
    "\n",
    "def create_string(str_list):\n",
    "    string = \"\"\n",
    "    for i in range(str_list):\n",
    "        string += str_list[i]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For husbands that don\\'t set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create columnn with complete prompt to be given to the LLM\n",
    "paraphrases = [\n",
    "            \"Imagine a self-contained, hypothetical world with only the following conditions, and without any unmentioned factors or causal relationships. \",\n",
    "            \"Think of a self-contained, hypothetical setting with just the specified conditions, and devoid of any unknown factors or causal connections. \",\n",
    "            \"Consider a self-contained, hypothetical world with solely the mentioned conditions, and is free from any hidden factors or cause-and-effect relationships. \",\n",
    "            \"Imagine a self-contained, hypothetical setting with merely the stated conditions, and absent any unmentioned factors or causative links. \",\n",
    "            \"Think of a self-contained, hypothetical world with only the given conditions, and is void of any unknown factors or causative relationships. \",\n",
    "        ]\n",
    "\n",
    "prompt_end0 = \"Extract the causal graph: Identify the causal graph that \\\n",
    "depicts the relationships in the scenario. \"\n",
    "prompt_end1 = 'The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.'\n",
    "prefix_end1 = 'The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:'\n",
    "prefix_end0 = \" Extract the causal graph: Identify the causal graph that \\\n",
    "depicts the relationships in the scenario. \"\n",
    "\n",
    "data['prompt'] = data.apply(lambda x: (prompt_end0+prompt_repres(x['reasoning'])+prompt_end1),axis=1)\n",
    "data['prefix'] = data.apply(lambda x: (x['given_info']+prefix_end0+prompt_repres(x['reasoning'])+prefix_end1),axis=1)\n",
    "\n",
    "#df = data[['prompt', 'formal_form', 'graph', 'query_type']]\n",
    "#data['prefix'].iloc[0]\n",
    "#data['prompt'].iloc[0]\n",
    "\n",
    "#/media/data/bazaluk/ctrlg_tulu2/data.csv\n",
    "data[['prompt','prefix','step1']].to_csv('/media/data/bazaluk/ctrlg_tulu2/data.csv')\n",
    "#data['prompt'].iloc[0]\n",
    "data['prefix'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bazaluk/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ceac2c01fc412fb0995c33878eeae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#######################################################################################################################\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # set your cuda device\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "import ctrlg\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# load the pretrained base_model and hmm_model;\n",
    "BASE_MODEL_PATH = f'ctrlg/tulu2-7b_writing-prompts'\n",
    "HMM_MODEL_PATH = f'ctrlg/hmm_tulu2-7b_writing-prompts_32768'\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH).to(device)\n",
    "base_model.eval()\n",
    "base_model.half() # fp16 inference\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "hmm_model = ctrlg.HMM.from_pretrained(HMM_MODEL_PATH).to(device)\n",
    "\n",
    "#######################################################################################################################\n",
    "## MY VERSION ##\n",
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "data = pd.read_csv('/media/data/bazaluk/ctrlg_tulu2/data.csv')\n",
    "data['pred_graphs'] = ''\n",
    "\n",
    "for i in range(3):\n",
    "#for i in range(len(data)):\n",
    "    vocab_size = hmm_model.vocab_size\n",
    "    eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "    prefix = data['prefix'].iloc[i]\n",
    "    d_prompt = data['prompt'].iloc[i]\n",
    "    suffix = '</s>'\n",
    "    soft_constraint = '' # use empty string for no soft constraint\n",
    "    prompt = f'<|user|>\\n\"{d_prompt}<|endoftext|>\"{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "\n",
    "    prefix_ids = tokenizer.encode(prefix)[1:]\n",
    "    suffix_ids = tokenizer.encode(suffix)[1:]\n",
    "    prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "    ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "    eos_builder = ctrlg.EOSBuilder(vocab_size, eos_token_id)\n",
    "\n",
    "\n",
    "    dfa_graphs = []\n",
    "    #keyphrases = [['towering'], ['reach the sky'], ['reflected'], ['lake']]\n",
    "    keyphrases = [[' X ', ' Y ', ' V2 ', ' V3 ', ' V4 ', ' V5 '],\n",
    "                    [' ->'],\n",
    "                     [' X ', ' Y ', ' V2 ', ' V3 ', ' V4 ', ' V5 ']\n",
    "                 ]\n",
    "\n",
    "    for keyphrase in keyphrases:\n",
    "        patterns = [tokenizer.encode(x)[1:] for x in keyphrase]\n",
    "        dfa_graphs.append(ac_builder.build(patterns))\n",
    "    dfa_graphs.append(eos_builder.build())\n",
    "\n",
    "\n",
    "    dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "    dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "    min_new_tokens = 1\n",
    "    max_new_tokens = 32\n",
    "    \n",
    "    ############################################################################\n",
    "    # initialze the constraints logits processor\n",
    "    constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "        hmm_model, dfa_model,\n",
    "        min_new_tokens, max_new_tokens,\n",
    "        prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "    # set the hmm_batch_size & temperature\n",
    "    beam_size = 32 # sample 128 sequences\n",
    "    temperature = 0.9\n",
    "    constraint_logits_processor.hmm_batch_size = beam_size\n",
    "    constraint_logits_processor.temperature = temperature\n",
    "\n",
    "\n",
    "    # generate with sampling, temperature=0.7\n",
    "    input_ids = torch.tensor([prompt_ids], device=device)\n",
    "    outputs = base_model.generate(\n",
    "            input_ids=input_ids, do_sample=True,\n",
    "            num_return_sequences=beam_size, \n",
    "            min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "            logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "\n",
    "    # extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "    generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "    # filter 75% of the generated ids by how well they connect with the suffix\n",
    "    generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids,\n",
    "                                                suffix_logits_only=True, suffix_length_cap=5)[:32]\n",
    "    # rank the generated ids by the base_model for higher quality\n",
    "    generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "    # save top 10 outputs\n",
    "    pred_graphs = []\n",
    "    for idx, generated in enumerate(generated_ids[:10]):\n",
    "        pred_graphs.append(tokenizer.decode(generated, skip_special_tokens=True) + \\\n",
    "              tokenizer.decode(suffix_ids, skip_special_tokens=True))\n",
    "    data.at[i, 'pred_graphs'] = pred_graphs\n",
    "\n",
    "data.to_csv('teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prefix</th>\n",
       "      <th>step1</th>\n",
       "      <th>pred_graphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>For husbands that don't set the alarm and wives that don't set the alarm, the probability of ringing alarm is 8%. For husbands that don't set the alarm and wives that set the alarm, the probability of ringing alarm is 54%. For husbands that set the alarm and wives that don't set the alarm, the probability of ringing alarm is 41%. For husbands that set the alarm and wives that set the alarm, the probability of ringing alarm is 86%. For husbands that don't set the alarm, the probability of alarm set by wife is 74%. For husbands that set the alarm, the probability of alarm set by wife is 24%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>{1: ['X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; Y', 'X -&gt; Y'], 10: ['V2 -&gt; Y', 'V2 -&gt; Y', 'V2 -&gt; Y', 'V2 -&gt; Y', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'V2 -&gt; X', 'V2 -&gt; X', 'X -&gt; Y'], 50: ['V2 -&gt; X', 'X -&gt; Y', 'X -&gt; Y', 'X -&gt; Y', 'X -&gt; Y', 'X -&gt; V1', 'X -&gt; V1', 'Y -&gt; X', 'Y -&gt; X', 'Y -&gt; X'], 100: ['V2 -&gt; Y', 'V2 -&gt; Y', 'V2 -&gt; X', 'V2 -&gt; Y , V1 -&gt; X', 'X -&gt; Y', 'X -&gt; Y', 'V1 -&gt; Y', 'V5 -&gt; X , V4 -&gt; X , V3 -&gt; Y , V2 -&gt; V5 , X -&gt; X', 'Y -&gt; X', 'Y -&gt; X']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>{1: ['X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; V2', 'X -&gt; Y'], 10: ['V1 -&gt; V2', 'X -&gt; V2', 'V2 -&gt; X', 'Y -&gt; V2', 'Y -&gt; V2', 'Y -&gt; V2', 'V1 -&gt; X', 'V1 -&gt; X', 'V2 -&gt; V2', 'X -&gt; Y'], 50: ['X -&gt; V2', 'V2 -&gt; X', 'V2 -&gt; X', 'Y -&gt; V2', 'V2 -&gt; X , V1 -&gt; Y', 'V2 -&gt; V2', 'X -&gt; Y , X -&gt; Y', 'X -&gt; Y', 'X -&gt; Y', 'X -&gt; Y'], 100: ['V2 -&gt; Y', 'X -&gt; V2', 'Y -&gt; V2', 'Y -&gt; V2', 'Y -&gt; V2', 'V1 -&gt; X', 'X -&gt; Y', 'X -&gt; Y', 'Y -&gt; X , X -&gt; Y', 'Y -&gt; V1']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>For husbands that don't set the alarm, the probability of ringing alarm is 20%. For husbands that set the alarm, the probability of ringing alarm is 68%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>For husbands that don't set the alarm and wives that don't set the alarm, the probability of ringing alarm is 11%. For husbands that don't set the alarm and wives that set the alarm, the probability of ringing alarm is 60%. For husbands that set the alarm and wives that don't set the alarm, the probability of ringing alarm is 46%. For husbands that set the alarm and wives that set the alarm, the probability of ringing alarm is 92%. For husbands that don't set the alarm, the probability of alarm set by wife is 61%. For husbands that set the alarm, the probability of alarm set by wife is 1%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;V2,X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>8527</td>\n",
       "      <td>8527</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>We know that zuph or jyka causes glimx. We observed an individual is jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>8528</td>\n",
       "      <td>8528</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>We know that zuph or jyka causes glimx. We observed an individual is jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>8529</td>\n",
       "      <td>8529</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>We know that zuph or jyka causes glimx. We observed an individual is jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>8530</td>\n",
       "      <td>8530</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>We know that zuph and jyka causes glimx. We observed an individual is not jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8531</th>\n",
       "      <td>8531</td>\n",
       "      <td>8531</td>\n",
       "      <td>Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas.</td>\n",
       "      <td>We know that zuph and jyka causes glimx. We observed an individual is not jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -&gt; var2\" format, separated by commas:</td>\n",
       "      <td>X-&gt;Y,V2-&gt;Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8532 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                0           0   \n",
       "1                1           1   \n",
       "2                2           2   \n",
       "3                3           3   \n",
       "4                4           4   \n",
       "...            ...         ...   \n",
       "8527          8527        8527   \n",
       "8528          8528        8528   \n",
       "8529          8529        8529   \n",
       "8530          8530        8530   \n",
       "8531          8531        8531   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                           prompt  \\\n",
       "0     Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "1     Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "2     Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "3     Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "4     Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "...                                                                                                                                                                                                                                                                                           ...   \n",
       "8527           Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "8528           Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "8529           Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "8530           Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "8531           Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                prefix  \\\n",
       "0     For husbands that don't set the alarm and wives that don't set the alarm, the probability of ringing alarm is 8%. For husbands that don't set the alarm and wives that set the alarm, the probability of ringing alarm is 54%. For husbands that set the alarm and wives that don't set the alarm, the probability of ringing alarm is 41%. For husbands that set the alarm and wives that set the alarm, the probability of ringing alarm is 86%. For husbands that don't set the alarm, the probability of alarm set by wife is 74%. For husbands that set the alarm, the probability of alarm set by wife is 24%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                        The overall probability of alarm set by husband is 77%. For husbands that don't set the alarm, the probability of ringing alarm is 26%. For husbands that set the alarm, the probability of ringing alarm is 76%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                For husbands that don't set the alarm, the probability of ringing alarm is 20%. For husbands that set the alarm, the probability of ringing alarm is 68%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "4     For husbands that don't set the alarm and wives that don't set the alarm, the probability of ringing alarm is 11%. For husbands that don't set the alarm and wives that set the alarm, the probability of ringing alarm is 60%. For husbands that set the alarm and wives that don't set the alarm, the probability of ringing alarm is 46%. For husbands that set the alarm and wives that set the alarm, the probability of ringing alarm is 92%. For husbands that don't set the alarm, the probability of alarm set by wife is 61%. For husbands that set the alarm, the probability of alarm set by wife is 1%. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use X to represent husband. Use V2 to represent wife. Use Y to represent alarm clock. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ...   \n",
       "8527                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We know that zuph or jyka causes glimx. We observed an individual is jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "8528                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We know that zuph or jyka causes glimx. We observed an individual is jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "8529                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     We know that zuph or jyka causes glimx. We observed an individual is jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "8530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We know that zuph and jyka causes glimx. We observed an individual is not jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "8531                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We know that zuph and jyka causes glimx. We observed an individual is not jyka. Extract the causal graph: Identify the causal graph that depicts the relationships in the scenario. Use V2 to represent jyka. Use X to represent zuph. Use Y to represent glimx. The diagram should simply consist of edges denoted in \"var1 -> var2\" format, separated by commas:   \n",
       "\n",
       "                 step1  \\\n",
       "0     X->V2,X->Y,V2->Y   \n",
       "1     X->V2,X->Y,V2->Y   \n",
       "2     X->V2,X->Y,V2->Y   \n",
       "3     X->V2,X->Y,V2->Y   \n",
       "4     X->V2,X->Y,V2->Y   \n",
       "...                ...   \n",
       "8527        X->Y,V2->Y   \n",
       "8528        X->Y,V2->Y   \n",
       "8529        X->Y,V2->Y   \n",
       "8530        X->Y,V2->Y   \n",
       "8531        X->Y,V2->Y   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               pred_graphs  \n",
       "0     {1: ['X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> Y', 'X -> Y'], 10: ['V2 -> Y', 'V2 -> Y', 'V2 -> Y', 'V2 -> Y', 'X -> V2', 'X -> V2', 'X -> V2', 'V2 -> X', 'V2 -> X', 'X -> Y'], 50: ['V2 -> X', 'X -> Y', 'X -> Y', 'X -> Y', 'X -> Y', 'X -> V1', 'X -> V1', 'Y -> X', 'Y -> X', 'Y -> X'], 100: ['V2 -> Y', 'V2 -> Y', 'V2 -> X', 'V2 -> Y , V1 -> X', 'X -> Y', 'X -> Y', 'V1 -> Y', 'V5 -> X , V4 -> X , V3 -> Y , V2 -> V5 , X -> X', 'Y -> X', 'Y -> X']}  \n",
       "1                   {1: ['X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> V2', 'X -> Y'], 10: ['V1 -> V2', 'X -> V2', 'V2 -> X', 'Y -> V2', 'Y -> V2', 'Y -> V2', 'V1 -> X', 'V1 -> X', 'V2 -> V2', 'X -> Y'], 50: ['X -> V2', 'V2 -> X', 'V2 -> X', 'Y -> V2', 'V2 -> X , V1 -> Y', 'V2 -> V2', 'X -> Y , X -> Y', 'X -> Y', 'X -> Y', 'X -> Y'], 100: ['V2 -> Y', 'X -> V2', 'Y -> V2', 'Y -> V2', 'Y -> V2', 'V1 -> X', 'X -> Y', 'X -> Y', 'Y -> X , X -> Y', 'Y -> V1']}  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...  \n",
       "8527                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN  \n",
       "8528                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN  \n",
       "8529                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN  \n",
       "8530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN  \n",
       "8531                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN  \n",
       "\n",
       "[8532 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.read_csv(\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[(k[0], k[1], v) for k, v in trans.items() if k[0] != tuple() or k[1] != tuple()]\n",
    "a=[1,2,3]\n",
    "b=[4,5,6]\n",
    "[(a[i],b[i]) for i in range(3) if a[i] != 2 and b[i] != 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Germany', 'Berlin')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= {\n",
    "  \"Germany\": \"Berlin\", \n",
    "  \"Canada\": \"Ottawa\", \n",
    "  \"England\": \"London\"\n",
    "}\n",
    "list(a.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(((), (29871,)), 2)]\n",
    "a[0][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
